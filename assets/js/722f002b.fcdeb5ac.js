"use strict";(self.webpackChunknewra=self.webpackChunknewra||[]).push([[328],{2092:(e,s,i)=>{i.r(s),i.d(s,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>c,metadata:()=>d,toc:()=>o});var n=i(4848),r=i(8453);const c={sidebar_position:4},a="WebScrappingJob",d={id:"knowledgebases/datasources/jobs/WebscrapingJob",title:"WebScrappingJob",description:"This file is located in Modules/WebScrapping/Jobs/WebscrapingJob.php path",source:"@site/docs/knowledgebases/datasources/jobs/WebscrapingJob.md",sourceDirName:"knowledgebases/datasources/jobs",slug:"/knowledgebases/datasources/jobs/WebscrapingJob",permalink:"/newra_documentation/docs/knowledgebases/datasources/jobs/WebscrapingJob",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/knowledgebases/datasources/jobs/WebscrapingJob.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"DataSyncService",permalink:"/newra_documentation/docs/knowledgebases/datasources/Service/DataSyncService"},next:{title:"TrainDataSourceJob",permalink:"/newra_documentation/docs/knowledgebases/datasources/jobs/TrainDataSourceJob"}},l={},o=[{value:"WebscrapingJob Class: A Deep Dive",id:"webscrapingjob-class-a-deep-dive",level:2},{value:"Class Signature",id:"class-signature",level:3},{value:"Properties",id:"properties",level:2},{value:"Methods",id:"methods",level:2},{value:"<code>__construct()</code>",id:"__construct",level:3},{value:"<code>middleware()</code>",id:"middleware",level:3},{value:"<code>handle(WebscrapingHelper $webscrapingHelper, DataspaceService $datasourceService)</code>",id:"handlewebscrapinghelper-webscrapinghelper-dataspaceservice-datasourceservice",level:3},{value:"<code>shouldProcessLink(string $link)</code>",id:"shouldprocesslinkstring-link",level:3},{value:"<code>isLinkExcluded(string $link)</code>",id:"islinkexcludedstring-link",level:3},{value:"<code>linkExistsInKnowledgebase(string $link)</code>",id:"linkexistsinknowledgebasestring-link",level:3},{value:"<code>isLimitExceeded(string $link)</code>",id:"islimitexceededstring-link",level:3},{value:"<code>saveTempJson(string $link)</code>",id:"savetempjsonstring-link",level:3}];function t(e){const s={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",ul:"ul",...(0,r.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(s.h1,{id:"webscrappingjob",children:"WebScrappingJob"}),"\n",(0,n.jsxs)(s.p,{children:["This file is located in ",(0,n.jsx)(s.code,{children:"Modules/WebScrapping/Jobs/WebscrapingJob.php"})," path"]}),"\n",(0,n.jsx)(s.h2,{id:"webscrapingjob-class-a-deep-dive",children:"WebscrapingJob Class: A Deep Dive"}),"\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.code,{children:"WebscrapingJob"})," facilitates web scraping operations as a Laravel queued job. This class interacts with services and jobs like ",(0,n.jsx)(s.code,{children:"DatasourceService"})," and ",(0,n.jsx)(s.code,{children:"TrainDataSourceJob"}),"."]}),"\n",(0,n.jsx)(s.h3,{id:"class-signature",children:"Class Signature"}),"\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.code,{children:"class WebscrapingJob implements ShouldQueue"})," indicates that this Laravel Job class is designed to be queued for background processing."]}),"\n",(0,n.jsx)(s.h2,{id:"properties",children:"Properties"}),"\n",(0,n.jsx)(s.p,{children:"These private properties store important data used during the web scraping process:"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.code,{children:"$url"}),": The URL to scrape."]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.code,{children:"$scrapAllUrl"}),": A flag to scrape all links found within a webpage."]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.code,{children:"$knowledgebaseId"}),", ",(0,n.jsx)(s.code,{children:"$userId"}),", ",(0,n.jsx)(s.code,{children:"$excludedUrls"}),", ",(0,n.jsx)(s.code,{children:"$autoTrain"}),", ",(0,n.jsx)(s.code,{children:"$parentId"}),": Various identifiers and flags that govern the scraping process."]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.code,{children:"$user"}),", ",(0,n.jsx)(s.code,{children:"$tokenKey"}),": Data related to the user and their token storage."]}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"methods",children:"Methods"}),"\n",(0,n.jsx)(s.h3,{id:"__construct",children:(0,n.jsx)(s.code,{children:"__construct()"})}),"\n",(0,n.jsx)(s.p,{children:"Initializes the job class with necessary parameters, setting up individual scraping tasks."}),"\n",(0,n.jsx)(s.h3,{id:"middleware",children:(0,n.jsx)(s.code,{children:"middleware()"})}),"\n",(0,n.jsxs)(s.p,{children:["Specifies that this job should use the ",(0,n.jsx)(s.code,{children:"SkipIfBatchCancelled"})," middleware, stopping execution if the batch is cancelled."]}),"\n",(0,n.jsx)(s.h3,{id:"handlewebscrapinghelper-webscrapinghelper-dataspaceservice-datasourceservice",children:(0,n.jsx)(s.code,{children:"handle(WebscrapingHelper $webscrapingHelper, DataspaceService $datasourceService)"})}),"\n",(0,n.jsx)(s.p,{children:"Processes the scraping task:"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Loads related KnowledgeBase instance and User object."}),"\n",(0,n.jsx)(s.li,{children:"Checks if the user's datasource limit is exceeded."}),"\n",(0,n.jsxs)(s.li,{children:["Starts URL scraping operation using ",(0,n.jsx)(s.code,{children:"WebscrapingHelper"}),"."]}),"\n",(0,n.jsxs)(s.li,{children:["If scraping fails, it logs the event through ",(0,n.jsx)(s.code,{children:"DatasourceService.createFailedDatasource()"}),"."]}),"\n",(0,n.jsxs)(s.li,{children:["Calculates token counts for successful scraping contents via ",(0,n.jsx)(s.code,{children:"TokenizerX"}),"."]}),"\n",(0,n.jsx)(s.li,{children:"Checks if storage tokens are sufficient, else cancels the batch."}),"\n",(0,n.jsxs)(s.li,{children:["Creates a new datasource from scraped content via ",(0,n.jsx)(s.code,{children:"DatasourceService.createFromText()"}),"."]}),"\n",(0,n.jsxs)(s.li,{children:["If ",(0,n.jsx)(s.code,{children:"auto_train"})," is enabled and creation is successful, adds ",(0,n.jsx)(s.code,{children:"TrainDataSourceJob"})," to the batch."]}),"\n",(0,n.jsxs)(s.li,{children:["If ",(0,n.jsx)(s.code,{children:"scrapAllUrl"})," is set, creates additional scraping tasks for detected internal links."]}),"\n"]}),"\n",(0,n.jsx)(s.h3,{id:"shouldprocesslinkstring-link",children:(0,n.jsx)(s.code,{children:"shouldProcessLink(string $link)"})}),"\n",(0,n.jsx)(s.p,{children:"Determines if the provided link should be scraped. It considers if the link is excluded, has been processed before, or exceeds user's limits."}),"\n",(0,n.jsx)(s.h3,{id:"islinkexcludedstring-link",children:(0,n.jsx)(s.code,{children:"isLinkExcluded(string $link)"})}),"\n",(0,n.jsxs)(s.p,{children:["Checks if the provided link is within ",(0,n.jsx)(s.code,{children:"excludedUrls"}),"."]}),"\n",(0,n.jsx)(s.h3,{id:"linkexistsinknowledgebasestring-link",children:(0,n.jsx)(s.code,{children:"linkExistsInKnowledgebase(string $link)"})}),"\n",(0,n.jsx)(s.p,{children:"Checks if the provided link is already a datasource in the user's knowledge base."}),"\n",(0,n.jsx)(s.h3,{id:"islimitexceededstring-link",children:(0,n.jsx)(s.code,{children:"isLimitExceeded(string $link)"})}),"\n",(0,n.jsx)(s.p,{children:"Checks if the datasource limit for the user is reached; also checks if the link has been processed before."}),"\n",(0,n.jsx)(s.h3,{id:"savetempjsonstring-link",children:(0,n.jsx)(s.code,{children:"saveTempJson(string $link)"})}),"\n",(0,n.jsx)(s.p,{children:"Keeps a temporary record of a link that's set to be processed. This aids in verifying if a link has been processed before and helps track the number of links processed so far. Stores these processed links in a JSON file named 'kb_ID.json', where 'ID' represents the knowledge base ID."}),"\n",(0,n.jsxs)(s.p,{children:["This class arranges the scraping of URLs, managing of resources, tracking the number of tokens involved, and the user's datasource limit. It interfaces with ",(0,n.jsx)(s.code,{children:"DatasourceService"})," and ",(0,n.jsx)(s.code,{children:"TrainDataSourceJob"})," concerning the creation of new datasources and optional auto-training."]})]})}function h(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,n.jsx)(s,{...e,children:(0,n.jsx)(t,{...e})}):t(e)}},8453:(e,s,i)=>{i.d(s,{R:()=>a,x:()=>d});var n=i(6540);const r={},c=n.createContext(r);function a(e){const s=n.useContext(c);return n.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function d(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),n.createElement(c.Provider,{value:s},e.children)}}}]);