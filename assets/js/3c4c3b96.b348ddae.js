"use strict";(self.webpackChunknewra=self.webpackChunknewra||[]).push([[360],{898:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});var t=n(4848),r=n(8453);const a={sidebar_position:7},o="TrainDataSourceJob",i={id:"knowledgebases/datasources/jobs/TrainDataSourceJob",title:"TrainDataSourceJob",description:"Route Directory",source:"@site/docs/knowledgebases/datasources/jobs/TrainDataSourceJob.md",sourceDirName:"knowledgebases/datasources/jobs",slug:"/knowledgebases/datasources/jobs/TrainDataSourceJob",permalink:"/docs/knowledgebases/datasources/jobs/TrainDataSourceJob",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/knowledgebases/datasources/jobs/TrainDataSourceJob.md",tags:[],version:"current",sidebarPosition:7,frontMatter:{sidebar_position:7},sidebar:"tutorialSidebar",previous:{title:"WebScrappingJob",permalink:"/docs/knowledgebases/datasources/jobs/WebscrapingJob"},next:{title:"listing",permalink:"/docs/knowledgebases/datasources/listing"}},c={},d=[{value:"Route Directory",id:"route-directory",level:2},{value:"Code Explanation",id:"code-explanation",level:2},{value:"Function Details",id:"function-details",level:3}];function l(e){const s={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.h1,{id:"traindatasourcejob",children:"TrainDataSourceJob"}),"\n",(0,t.jsx)(s.h2,{id:"route-directory",children:"Route Directory"}),"\n",(0,t.jsx)(s.p,{children:"Paths related to this job class will follow nothing specific as it's a job which can by definition be dispatched from anywhere in the Laravel application."}),"\n",(0,t.jsx)(s.h2,{id:"code-explanation",children:"Code Explanation"}),"\n",(0,t.jsxs)(s.p,{children:["This Laravel Job is designed around managing the training of data sources after they have been saved in ",(0,t.jsx)(s.code,{children:"TextScrappingController"}),"."]}),"\n",(0,t.jsx)(s.h3,{id:"function-details",children:"Function Details"}),"\n",(0,t.jsxs)(s.ol,{children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"construct(array $datasourceIds, User $user):"})}),"\n",(0,t.jsxs)(s.p,{children:["When a new instance of this job is created, the constructor receives an array of datasource IDs and a user instance. It initializes the ",(0,t.jsx)(s.code,{children:"DataSyncService"})," and assigns the ID array and the user to properties for later use."]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"handle():"})}),"\n",(0,t.jsx)(s.p,{children:"This method is the core of the job and is responsible for processing the datasource training. It systematically:"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:"Prepares crawler data which includes information on the module name, user ID, and event type."}),"\n",(0,t.jsx)(s.li,{children:"Chunks the list of datasources into groups of 20. This can be modified for efficiency based on hardware capabilities and requirements."}),"\n",(0,t.jsxs)(s.li,{children:["Iterates over these chunks, and for each datasource, it changes their status to 'training_requested' and saves them. It then generates a vector request for each datasource and sends the vector request to the ",(0,t.jsx)(s.code,{children:"DataSyncService"}),"."]}),"\n",(0,t.jsx)(s.li,{children:"Checks the active subscription for the user and retrieves the remaining storage tokens this user has left on their subscription."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"getRemainingStorageToken($subscription):"})}),"\n",(0,t.jsx)(s.p,{children:"A private helper method to calculate the remaining storage tokens, if the user has an active subscription. Returns the number of storage tokens the user has left."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.p,{children:["In summary, the ",(0,t.jsx)(s.code,{children:"TrainDataSourceJob"})," job primarily handles the queueable task of setting up data sources for training. This involves checking the users' remaining storage tokens and preparing and sending vector requests to the ",(0,t.jsx)(s.code,{children:"DataSyncService"})," for each valid datasource. The job is designed to systematically process requests for efficient usage of resources."]})]})}function h(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}},8453:(e,s,n)=>{n.d(s,{R:()=>o,x:()=>i});var t=n(6540);const r={},a=t.createContext(r);function o(e){const s=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function i(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(a.Provider,{value:s},e.children)}}}]);